
#
# Business Index: Dataload Configuration
# ======================================
#
# Changing configuration settings at runtime:
#
# This config file provides a vanilla default value, as shown below.
#
# It also allows the property to be overridden via a specified env variable if provided.
#
# The environment variable is named like this:
#
#   e.g. config property:        bi-dataload.es.index
#        corresponding variable: BI_DATALOAD_ES_INDEX
#
# So you can override config values here at runtime either via Java driver options
# or via environment variables.
#
# (a) via command-line Java driver options (e.g. in Oozie):
#
# spark-submit --class com.example.Sparky \
#              --master local[*] \
#              --driver-java-options "-Dbi-dataload.es.index=my_index_name" \
# target/scala-2.11/spark-dummy_2.11-1.0.jar
#
# (b) via a corresponding environment variable such as BI_DATALOAD_ES_INDEX.
#
# See the config parameters below for the corresponding environment variable names.
#
# Priority of config values:
#
# 1.  If value is provided via Java driver option, then this value will be used.
# 2.  Else if value is provided via env variable, then this value will be used.
# 3.  Else if no env or driver value exists, then value from config file will be used.
#

bi-dataload {

  # User directory
  env = "dev"
  env = ${?BI_DATALOAD_APP_DATA_ENV}

  # parameter for determining if running on cluster or local for spark
  cluster = "local"
  cluster = ${?BI_DATALOAD_CLUSTER}

  # Directory and files for external data
  external {

    ext-dir = "external"
    ext-dir = ${?BI_DATALOAD_EXT_DATA_DIR}

    ch-dir = "companiesHouse"
    ch-dir = ${?BI_DATALOAD_EXT_DATA_CH_DIR}
    vat-dir = "hmrc/vat"
    vat-dir = ${?BI_DATALOAD_EXT_DATA_VAT_DIR}
    paye-dir = "hmrc/paye"
    paye-dir = ${?BI_DATALOAD_EXT_DATA_PAYE_DIR}
    lookups-dir = "lookups"
    lookups-dir = ${?BI_DATALOAD_LOOKUPS_DIR}

    paye = "PAYE.csv"
    paye = ${?BI_DATALOAD_EXT_DATA_PAYE}
    vat = "VAT.csv"
    vat = ${?BI_DATALOAD_EXT_DATA_VAT}
    ch = "CH.csv"
    ch = ${?BI_DATALOAD_EXT_DATA_CH}
    tcn-to-sic = "tcn-to-sic-mapping.csv"
    tcn-to-sic = ${?BI_DATALOAD_LOOKUPS_TCN_TO_SIC}
  }

  businessIndex {

    bi-dir = "businessIndex"
    bi-dir = ${?BI_DATALOAD_BI_DIR}

    # Output directory for elasticsearch
    elastic-dir = "ESOUTPUT"
    elastic-dir = ${?BI_DATALOAD_ELASTIC_DIR}

    # Previous Links output
    previous-dir = "PREVIOUS"
    previous-dir = ${?BI_DATALOAD_PREVIOUS_DIR}

    # HMRC output directory
    extract-dir = "EXTRACT"
    extract-dir = ${?BI_DATALOAD_EXTRACT_DIR}

    # Output Directory
    working-data-dir = "WORKINGDATA"
    working-data-dir = ${?BI_DATALOAD_WORKING_DIR}

    # Data Science input file
    data-science-dir = "bi-parquet"
    data-science-dir = ${?BI_DATALOAD_PARQUET_DIR}
    data-science = "legal_units.parquet"
    data-science = ${?BI_DATALOAD_PARQUET_DATA_SCIENCE}

    # BI output files
    bi = "BI_Output.parquet"
    bi = ${?BI_DATALOAD_PARQUET_BI}
    links = "LINKS_Output.parquet"
    links = ${?BI_DATALOAD_PARQUET_LINKS}

    # Admin units parquet
    ch = "CH.parquet"
    ch = ${?BI_DATALOAD_PARQUET_CH}
    paye = "PAYE.parquet"
    paye = ${?BI_DATALOAD_PARQUET_PAYE}
    vat = "VAT.parquet"
    vat = ${?BI_DATALOAD_PARQUET_VAT}
    tcn = "TCN_TO_SIC_LOOKUP.parquet"
    tcn = ${?BI_DATALOAD_PARQUET_TCN}

  }

  # ElasticSearch config

  es {
    nodes = "localhost"
    nodes = ${?BI_DATALOAD_ES_NODES}
    port = 9200
    port = ${?BI_DATALOAD_ES_PORT}
    es-user = "username"
    es-user = ${?BI_DATALOAD_ES_USER}
    es-pass = "password"
    es-pass = ${?BI_DATALOAD_ES_PASS}
    index = "bi-dev"
    index = ${?BI_DATALOAD_ES_INDEX}
    index-type = "business"
    index-type = ${?BI_DATALOAD_ES_INDEX_TYPE}
    # We expect the real index to exist already as it needs extra config that cannot be done here.
    # But using autocreate allows us to test with arbitrary index names.
    autocreate = "true"
    autocreate = ${?BI_DATALOAD_ES_AUTOCREATE}
    # WAN-only not used currently but may be needed (cf. Address Index)
    wan-only = "true"
    wan-only = ${?BI_DATALOAD_ES_WAN_ONLY}
  }

  # Any default params we might want to provide for Spark
  spark {
    app-name = "business-indexes-dataload"
    app-name = ${?BI_DATALOAD_SPARK_APP_NAME}
    serializer = "org.apache.spark.serializer.KryoSerializer"
    serializer = ${?BI_DATALOAD_SPARK_SERIALIZER}
  }

}