
dataload {

  # One approach is to provide a vanilla default value
  # then allow it to be over-ridden by a value provided:
  #
  # (a) at runtime via command-line Java driver options:
  #
  # spark-submit --class com.example.Sparky \
  #              --master local[*] \
  #              --driver-java-options "-Dmy-app.es-config.host=my.host.com" \
  # target/scala-2.11/spark-dummy_2.11-1.0.jar
  #
  # or (b) as an environment variable such as MY_APP_ES_CONFIG_HOST

  es-config {
    host="localhost"
    host = ${?MY_APP_ES_CONFIG_HOST}
    port = 9020
    port = ${?MY_APP_ES_CONFIG_PORT}
    reps = 3
    reps = ${?MY_APP_ES_CONFIG_REPS}
  }




  src-data {
    dir =  "./temp-data"
    dir =${?DATALOAD_SRC_DATA_DIR}
    paye = "PAYE_Output.csv"
    paye =${?DATALOAD_SRC_DATA_PAYE}
    vat = "VAT_Output.csv"
    vat =${?DATALOAD_SRC_DATA_VAT}
    ch = "CH_Output.csv"
    ch =${?DATALOAD_SRC_DATA_CH}
    links = "exact.json"
    links =${?DATALOAD_SRC_DATA_LINKS}
  }

  parquet-data {
    dir =  "./temp-data"
    dir =${?DATALOAD_PARQUET_DATA_DIR}
    paye = "PAYE_Output.parquet"
    paye =${?DATALOAD_PARQUET_DATA_PAYE}
    vat = "VAT_Output.parquet"
    vat =${?DATALOAD_PARQUET_DATA_VAT}
    ch = "CH_Output.parquet"
    ch =${?DATALOAD_PARQUET_DATA_CH}
    links = "exact.parquet"
    links =${?DATALOAD_PARQUET_DATA_LINKS}
  }
}